%{
enssc.m
  This is the matlab implementation of Enssembles: Tre Classifier
  It's called from hsi_classifiers_kmeans.m.
  The data should be structured before run it.

  Inputs:
      predictors: Predictors structured
      response:   Response vector  
      train_id:   Train set
      test_id:    Test set
      file:       Result file
%}
function classifier = enssc(predictors, response, train_id, test_id, file)
  load(file,'results');
  
  fprintf('\n\nEnssembles: Tree Classifier\n');
  template = templateTree(); 
  classifier = fitcensemble(...
    predictors(train_id,:), ...
    response(train_id), ...
    'Learners', template, ...
    'ClassNames', unique(response(train_id)), ...
    'OptimizeHyperparameters', 'all', ...
    'HyperparameterOptimizationOptions', struct('Holdout',0.3, ...
    'AcquisitionFunctionName', 'expected-improvement-plus', ...
    'UseParallel', true, ...
    'ShowPlots', false, ...
    'Verbose', 1));
      
  fprintf('Min Objective: %s\n', num2str(classifier.HyperparameterOptimizationResults.MinObjective));
  [label,~] = predict(classifier,predictors(test_id,:));
  total = cellfun(@strcmp, response(test_id), label);
  hits = total(total==1);
  accuracy = size(hits,1)/size(total,1);
  fprintf('Accuracy in test data: %s%%\n', num2str(accuracy*100));
  disp(classifier.ModelParameters);
  
  %   Save results
  row = size(results,1)+1;
  results{row,1} = classifier.ModelParameters;
  results{row,2} = accuracy*100;
  results{row,3} = label;
  save(file,'results');
  
  fprintf('\n\nEnssembles: KNN Classifier - Optimize All HyperParameters\n');
  template = templateKNN(...
    'NSMethod','kdtree');
  
  subspaceDimension = max(1, min(3, width(predictors(train_id,:)) - 1));
  classifier = fitcensemble(...
    predictors(train_id,:), ...
    response(train_id), ...
    'Learners', template, ...
    'Method', 'Subspace', ...
    'NPredToSample', subspaceDimension, ...
    'ClassNames', unique(response(train_id)), ...
    'OptimizeHyperparameters', {'NumLearningCycles','NumNeighbors','Distance','DistanceWeight','Exponent','Standardize'}, ...
    'HyperparameterOptimizationOptions', struct('Holdout',0.3, ...
    'UseParallel', true, ...
    'ShowPlots', false, ...
    'Verbose', 1));
      
  fprintf('Min Objective: %s\n', num2str(classifier.HyperparameterOptimizationResults.MinObjective));
  [label,~] = predict(classifier,predictors(test_id,:));
  total = cellfun(@strcmp, response(test_id), label);
  hits = total(total==1);
  accuracy = size(hits,1)/size(total,1);
  fprintf('Accuracy in test data: %s%%\n', num2str(accuracy*100));
  disp(classifier.ModelParameters);
  
  %   Save results
  row = size(results,1)+1;
  results{row,1} = classifier.ModelParameters;
  results{row,2} = accuracy*100;
  results{row,3} = label;
  save(file,'results');
  
  disp('Enssembles: KNN Classifier - Optimize Minkowski Distance Exponent');

  template = templateKNN(...
    'Distance', 'minkowski',...
    'NSMethod', 'kdtree');
  
  subspaceDimension = max(1, min(3, width(predictors(train_id,:)) - 1));
  classifier = fitcensemble(...
    predictors(train_id,:), ...
    response(train_id), ...
    'Learners', template, ...
    'Method', 'Subspace', ...
    'NPredToSample', subspaceDimension, ...
    'ClassNames', unique(response(train_id)), ...
    'OptimizeHyperparameters', {'NumLearningCycles','NumNeighbors','DistanceWeight','Exponent','Standardize'}, ...
    'HyperparameterOptimizationOptions', struct('Holdout',0.3, ...
    'UseParallel', true, ...
    'ShowPlots', false, ...
    'Verbose', 1));
      
  fprintf('Min Objective: %s\n', num2str(classifier.HyperparameterOptimizationResults.MinObjective));    
  [label,~] = predict(classifier,predictors(test_id,:));
  total = cellfun(@strcmp, response(test_id), label);
  hits = total(total==1);
  accuracy = size(hits,1)/size(total,1);
  fprintf('Accuracy in test data: %s%%\n', num2str(accuracy*100));
  disp(classifier.ModelParameters);

  %   Save results
  row = size(results,1)+1;
  results{row,1} = classifier.ModelParameters;
  results{row,2} = accuracy*100;
  results{row,3} = label;
  save(file,'results');
  
  disp('Enssembles: Discriminant Classifier');

  template = templateDiscriminant();
  subspaceDimension = max(1, min(3, size(predictors(train_id,:),1) - 1));
  classifier = fitcensemble(...
    predictors(train_id,:), ...
    response(train_id), ...
    'Learners', template, ...
    'Method', 'Subspace', ...
    'NPredToSample', subspaceDimension, ...
    'ClassNames', unique(response(train_id)), ...
    'OptimizeHyperparameters', {'NumLearningCycles','Delta','DiscrimType','Gamma'}, ...
    'HyperparameterOptimizationOptions', struct('Holdout',0.3, ...
    'UseParallel', true, ...
    'ShowPlots', false, ...
    'Verbose', 1));
      
  fprintf('Min Objective: %s\n', num2str(classifier.HyperparameterOptimizationResults.MinObjective));
  [label,~] = predict(classifier,predictors(test_id,:));
  total = cellfun(@strcmp, response(test_id), label);
  hits = total(total==1);
  accuracy = size(hits,1)/size(total,1);
  fprintf('Accuracy in test data: %s%%\n', num2str(accuracy*100));
  disp(classifier.ModelParameters);
  
  %   Save results
  row = size(results,1)+1;
  results{row,1} = classifier.ModelParameters;
  results{row,2} = accuracy*100;
  results{row,3} = label;
  save(file,'results');
end